Below is a deep technical review of the crate as it exists in the attached source tree (notably `crates/canopy/` and `crates/canopy-derive/`). I’m treating this as a “post‑refactor” API/implementation assessment: correctness first, then conceptual coherence, then ergonomics/performance.

I’m referencing concrete symbols/files so you can turn this into issues/PRs quickly.

---

## Architectural read of the current design

At a high level, the system has a clean “three‑layer” shape:

1. **World / tree + layout**: `core/world.rs` (`Core`) owns the node arena (`SlotMap<NodeId, Node>`), focus, and the full layout pass (`LayoutPass`). Layout is a two‑stage computation:

   * measure/layout (`layout_node`, `measure_*`)
   * view computation (`update_views`) including scroll offsets (`view.tl`) and visible rects (`view.outer`, `view.content`).

2. **Rendering and diff**:

   * `core/render.rs` provides the immediate-mode drawing API into a `TermBuf`.
   * `core/termbuf.rs` performs diffing between frames; backend applies ops (`write`, `clear`, optional shift ops).

3. **Interaction and scripting**:

   * `core/canopy.rs` glues everything together: event dispatch, keymap resolution, script execution, render traversal.
   * Commands are compiled into Rhai modules (`core/script.rs`) using `CommandSpec`/`CommandNode` (generated by `canopy-derive`).

This is a reasonable split. The refactor seems to have pushed the crate towards:

* a stable “widget tree + context” model,
* dynamic scripting as the universal binding target (even for typed bindings),
* a layout engine that is “mostly CSS-ish” with flex/grow, wrap content, etc.

The biggest problems I found are not in the overall architecture, but at the **boundaries**:

* unsafe script dispatch plumbing,
* parent/child invariants when reparenting,
* precedence/semantics mismatches (input matching, event→render contract),
* several correctness nits (actual bugs),
* and some public API exposure that will make future refactors painful.

---

## Bugs and correctness issues

### 1) **Unsound `ScriptGlobal` access in `ScriptHost::load_commands` (UB risk)**

**Where**

* `crates/canopy/src/core/script.rs`, `ScriptHost::load_commands` closure, around line ~129:
  `let sg = unsafe { &mut *(*ptr as *mut ScriptGlobal) };`

**Why it’s wrong**

* The thread-local stores a `*const ()` (in practice derived from `&sg`) and later casts it to `*mut ScriptGlobal` and creates a `&mut ScriptGlobal`.
* That is *not* a valid provenance / mutability story. Even if it “works on today’s compiler”, it is UB under Rust’s aliasing model.

**What to do**

* Store a `*mut ScriptGlobal` in TLS, derived from an actual `&mut ScriptGlobal` that lives for the duration of the execute call.
* Better yet: store raw pointers to the **actual mutable things you need** (`*mut Core`, `NodeId`) to avoid lending `&mut ScriptGlobal` at all.

**Minimal repair sketch**

* Change TLS to `Cell<*mut ScriptGlobal>` (or `*mut ()` but consistently).
* In `execute`, create `let mut sg = ScriptGlobal { … }`, then `let sg_ptr: *mut ScriptGlobal = &mut sg;` and set TLS to that pointer for the duration.
* In the registered functions, read TLS and `unsafe { &mut *sg_ptr }` where `sg_ptr` is genuinely `*mut`.

If you want to avoid UB *and* reduce unsafe surface further, consider making `ScriptGlobal`:

```rust
struct ScriptGlobal {
    core: *mut Core,
    node_id: NodeId,
}
```

and then only ever `unsafe`-dereference `core` inside the function call boundary.

**Severity**: High. This is the kind of issue that can become a miscompile.

---

### 2) **`Core::set_children` can corrupt the tree when children already have a different parent**

**Where**

* `crates/canopy/src/core/world.rs`, `Core::set_children` (around lines ~189–212).

**Problem**

* You assign `node.parent = Some(parent)` for each child in the new vector, but you do **not** detach it from its previous parent’s `children` list.
* Result: a node can appear in multiple parents’ `children` vectors; traversal/layout/render will become inconsistent (and can loop strangely if combined with other mistakes).

**Fix options**

* **Strict**: return an error if any `child.parent` is `Some(old)` where `old != parent)`.
* **Permissive** (likely what you want): detach first.

Concrete approach:

* For every incoming child:

  * if `child.parent == Some(old_parent)` and `old_parent != parent`, call `detach_child(old_parent, child)` before reparenting.
  * also consider guarding against cycles (`child` must not be an ancestor of `parent`).

**Severity**: High. This is a structural invariant violation.

---

### 3) **`Core::set_widget` does not reset `initialized`; new widget may never receive `poll()`**

**Where**

* `crates/canopy/src/core/world.rs`, `Core::set_widget` (around lines ~140–154).

**Problem**

* Replacing a widget sets `mounted = false` but leaves `initialized` untouched.
* Since `pre_render` only calls `poll()` if `!initialized`, a replaced widget can silently skip its poll initialization forever.

**Fix**

* In `set_widget`, set:

  * `node.mounted = false;`
  * `node.initialized = false;`  ← required
  * (optional) clear other widget-coupled state that shouldn’t survive replacement (e.g. `effects`, `clear_inherited_effects`, scroll? depends on intent).

**Severity**: Medium/High (depends on how often `set_widget` is used in real apps).

---

### 4) **Crossterm media key mapping bug**

**Where**

* `crates/canopy/src/core/backend/crossterm.rs`, `translate_event`, media keys.

**Bug**

* `cevent::MediaKeyCode::Pause => key::MediaKeyCode::Play`
  Pause maps to Play.

**Fix**

* Map to `MediaKeyCode::Pause`.

**Severity**: Low, but clearly wrong.

---

### 5) **Inspector default key bindings contain a clear mistake**

**Where**

* `crates/canopy/src/widgets/inspector/mod.rs`, `impl DefaultBindings for Inspector`:

  ```rust
  .key(KeyCode::Down, "logs::select_next()")
  .key(KeyCode::Down, "logs::select_prev()")
  ```

Second binding overwrites the first, and Up is never bound.

**Fix**

* Second should be `KeyCode::Up`.

**Severity**: Low, but it breaks a shipped default UX.

---

### 6) **Unicode width handling is inconsistent and will break horizontal clipping/scrolling**

This is less “one-line bug” and more “systemic correctness gap”.

**Where**

* `core/render.rs` `Render::text` truncation uses `.chars()` indices and counts.
* `widgets/text.rs` rendering slices by `char_indices()` using `view_rect.tl.x` as “char offset”.

**Problem**

* Terminal cell width is not `chars().count()` for non-ASCII / wide glyphs.
* You already depend on `unicode_width`, and `Text::measure` uses it, so measurement and rendering can disagree.

**Fix direction**

* Introduce a shared utility that slices a string by **display columns** (UnicodeWidthChar), not scalar values:

  * `byte_index_at_column(s, col) -> usize`
  * `take_columns(s, cols) -> (&str, used_cols)`
* Use that in both `Render::text` and `Text::render` (and any other text-like widget).

**Severity**: Medium if you care about Unicode correctness; otherwise document “ASCII-only” explicitly (but then measurement should match).

---

### 7) Potential UB: `editor/primitives.rs` uses `offset_from` on `str` slices

**Where**

* `crates/canopy/src/widgets/editor/primitives.rs`, `wrap_offsets`, around:

  ```rust
  unsafe { word.line.as_ptr().offset_from(s.as_ptr()) }
  ```

**Concern**

* `offset_from` requires both pointers are into the **same allocation**. If `textwrap` ever produces a `&str` not borrowed from `s` (e.g., via internal allocation for broken words), this is UB.

I can’t prove from this repo alone that `textwrap` 0.16.2 always returns slices into the original input for your call pattern; it’s likely, but not something I would “unsafe” on.

**Fix**

* Track offsets without pointer arithmetic:

  * Prefer upstream APIs that provide source indices (if available).
  * Or compute offsets by walking `s.char_indices()` while consuming the same slices.
  * Or store ranges when initially tokenizing.

**Severity**: Potentially high because it’s UB, but contingent on upstream behavior.

---

## Conceptual and structural problems worth addressing

### A) The “event→render contract” is currently internally inconsistent

**Observation**

* `Widget::on_event` returns `EventOutcome::{Handle, Consume, Ignore}` and `Canopy.key/mouse` compute `render_needed: bool`.
* But `Canopy.event()` discards those booleans, and `core/backend/crossterm::runloop` renders *unconditionally* after every event.

**Why this matters**

* Either:

  * you intend to always render (simpler; then `Handle/Consume` only affects propagation), or
  * you intend incremental/conditional rendering (then the current runloop and `Canopy.event` are incomplete).

**Recommendation**
Pick one of these and make it explicit:

1. **Always-render model (simplify)**

   * Change `Canopy.key/mouse` to return `Result<EventOutcome>` or just `Result<()>`.
   * Keep `Consume` vs `Handle` only for propagation semantics, not render scheduling.
   * Remove `render_needed` logic.

2. **Conditional-render model (optimize)**

   * Change `Canopy.event(&mut self, event) -> Result<bool>` returning “needs render”.
   * In runloop, call render only when true.
   * Make `Poll` and `Resize` return true.
   * Ensure focus changes also force a render (when you stop unconditional rendering, this becomes critical).

Given you already have a diff backend and a layout engine, conditional rendering is a logical next step. But if you want correctness/clarity now, simplify first and reintroduce optimization deliberately later.

---

### B) Public API surface is exposing internal invariants you will want to change

Right now, many internals are `pub`:

* `Canopy` exposes `poller`, `keymap`, `commands`, `script_host`, `style`, `core`, and even `event_rx: Option<Receiver<Event>>`.
* `Core` exposes `nodes`, `root`, `focus`, `layout_dirty`, etc.
* `Node` fields are almost entirely public.

This makes it very hard to evolve the implementation without breaking downstream crates or allowing users to violate invariants (tree structure, mount state, view consistency).

**Recommendation**

* Decide what your “stable surface” is.
* Make `Node` and `Core` fields private (or `pub(crate)`), and provide read-only accessors and safe mutation methods.
* If you want to keep a power-user escape hatch, provide something like:

  * `Core::debug_nodes()` returning iterators/views, not mutable references.
  * explicit `unsafe fn nodes_mut_unchecked()` if you truly need it (but keep it out of normal code).

This is one of the biggest “future refactor tax” reducers you can do.

---

### C) `set_children` vs `mount_child`: tree editing API is too permissive without guardrails

You currently have:

* `mount_child` (safe-ish; detaches prior parent)
* `set_children` (fast but unsafe logically unless caller obeys rules)
* `detach_child`

Given how easy it is to corrupt the tree via `set_children`, you should either:

* enforce invariants inside `set_children`, or
* rename it to something that screams “unsafe unless children are already mine”, or
* make it private and expose a safe wrapper that detaches/reparents correctly.

I’d strongly lean towards **making `set_children` safe by construction**, even if it’s a little slower.

---

### D) Input path matching semantics are clever, but precedence is underspecified

`InputMode::resolve` chooses the binding with the largest `match.end()` index. That biases toward deeper matches, which is probably what you want, but it creates unintuitive ties:

* Path `/root/bar/foo`
* Filter `foo` matches ending at same index as filter `bar/foo`
* If both are bound, whichever was bound first wins (because you only update on `p > ret.0`).

**Recommendation**
Change the scoring from a single integer to a tuple:

* primary: match end (depth)
* secondary: match length (specificity)
* tertiary: binding order (last-one-wins is usually friendlier for config overlays)

That gives you deterministic, intuitive precedence and makes user overrides predictable.

---

### E) Mode behavior likely isn’t what users expect

`InputMap::resolve` only checks the current mode. When you set a non-default mode, your default/global bindings stop working unless duplicated.

Most TUI frameworks treat modes as overlays (mode-specific binds override global ones, not replace them).

**Recommendation**

* Resolve against `current_mode`, and if nothing matches, fall back to default (`""`).
* Or treat default mode as always-active layer.

---

### F) Script integration is powerful, but “typed commands compile to strings” is leaving performance and ergonomics on the table

Your typed command API (`CommandRef`, `CommandCall`) still produces a script string which is compiled into Rhai.

That gives flexibility (you can still write arbitrary scripts), but it’s a heavy pipeline for simple “key → call method” bindings, and it inherits all the scripting safety/robustness requirements.

**Recommendation**
Support *two* binding targets:

1. **Direct command invocation**: store `CommandInvocation` (or a compact encoded form) directly in the keymap.
2. **Script**: store `ScriptId` for arbitrary scripts.

This will:

* reduce runtime overhead and latency for common interactions,
* reduce your dependency on Rhai correctness for core UX,
* let you keep Rhai for power users without making it the only route.

You already have the machinery (`dispatch` and `CommandInvocation`). This is not a huge lift.

---

## Low-hanging fruit: features and ergonomics wins

These are relatively small changes with high payoff.

### 1) Fix `set_children` invariants (mentioned above)

It’s both correctness and ergonomics: users shouldn’t have to reason about “is this child still referenced elsewhere”.

### 2) Make mode resolution layered (default + current)

Very small change, large UX improvement.

### 3) Improve precedence scoring for bindings

Also small, and it makes configuration overrides sane.

### 4) Clean up naming: `taint()` is not discoverable

`ViewContext::taint` currently means “mark layout dirty / invalidate layout”.

Rename or alias to something like:

* `invalidate_layout()`
* `request_layout()`
* `mark_layout_dirty()`

If you keep `taint` internally, still provide a more obvious alias on the public trait.

### 5) `StyleMap: Default` should be safe

Right now `StyleMap::new()` guarantees a fully specified default style, but `StyleMap` *also* derives `Default`, which yields an empty map.

That is a footgun: `StyleManager::resolve()` will `.unwrap()` and panic if the style chain never becomes complete.

**Fix**

* Implement `Default for StyleMap { fn default() -> Self { Self::new() } }`
* Don’t derive `Default` in a way that breaks invariants.

### 6) Make `ScriptHost::execute` optionally return the script value

Right now you ignore the `Dynamic` return from Rhai and return only `Result<()>`.

If you ever want REPL/console scripting or debug tooling, returning the value is extremely useful:

* `execute(...) -> Result<rhai::Dynamic>`
* or `execute_value(...)`, keep `execute` as discard.

### 7) Avoid per-node allocations in render effects

Current `render_traversal` clones vectors and allocates `effect_refs` every node.

Switch to a stack of `&dyn StyleEffect` and pass slices:

* push local effects
* render children
* pop back to previous length

It’s straightforward and keeps the “effects are inherited” model.

---

## Larger structural recommendations to improve ergonomics long-term

### 1) Separate “layout dirty”, “view dirty”, and “render dirty”

Right now you have:

* `Core.layout_dirty` used for anything that might affect render (including scrolling, style changes in places, etc.)
* per-node `layout_dirty` for re-fetching `widget.layout()`

If you want to stop doing full layout every event (which you almost certainly will), you need a clearer pipeline:

* **Layout dirty**: requires measure/layout pass (`LayoutPass`)
* **View dirty**: requires `update_views` (scroll changes, viewport changes)
* **Render dirty**: requires redraw/diff only

This enables:

* scrolling without re-measuring,
* style changes without layout,
* cheap cursor/focus updates.

Even if you still render every event, having the flags cleanly separated will make optimizations safe later.

---

### 2) Make “mount / unmount” semantics explicit and consistent

You have `on_mount`, but no unmount hook and no node removal.

As your widget set grows (terminal/editor), lifecycle becomes important for:

* stopping poll schedules,
* releasing resources,
* shutting down background threads,
* detaching children safely.

Consider:

* `Widget::on_unmount(&mut self, ctx: &mut dyn Context)` (called when detached or removed)
* a real `Core::remove(node)` (with subtree removal), or at minimum a “deactivate” concept.

If you don’t want actual removal (because `NodeId` stability is valuable), provide a GC-like “drop unreachable” pass.

---

### 3) Disentangle “node identity” from “node type name”

Right now:

* `NodeName` is effectively the widget type name converted to snake case (unless overridden).
* Path matching and command dispatch are based on this.
* Multiple instances of the same widget type become ambiguous to target.

Consider adding **instance tags**:

* Keep `kind: NodeName` (type)
* Add `id: Option<String>` or `tag: Option<NodeName>` (instance identity)
* Path matching can use `tag` when present; command module dispatch can remain on `kind`.

This single feature dramatically improves ergonomics for large apps (multiple lists, panes, editors, etc.).

---

### 4) Rework command registration to reduce boilerplate and failure modes

Requiring `Canopy::add_commands::<T>()` is workable but error-prone (bind script before load → compile fails).

Options:

* Auto-register commands when the widget type is first mounted/added (needs type registry).
* Or make script compilation lazy (compile on first use; requires deferring errors).
* Or provide a `Loader` that’s compositional and easy to apply at root (you already have `Loader`, but it’s manual).

If you keep explicit registration, improve errors:

* when compile fails due to missing module, report “did you forget add_commands::<T>()?” and list known modules.

---

### 5) Reduce unsafe surface in `Core::with_widget_*`

Your `with_widget_mut`/`with_widget_view` pattern is common in arena-based GUI trees, but it’s brittle:

* relies on taking the widget out of the node,
* will lose the widget if a panic occurs mid-closure,
* has reentrancy hazards (calling `with_widget_mut` on the same node while it’s taken).

If you keep this approach, at least make it panic-safe via a guard that reinserts the widget in `Drop` (RAII).

Longer-term alternatives (depending on your goals):

* store widgets in a separate arena so you can borrow node metadata and widget independently,
* or store widgets behind `RefCell` (trade runtime checks for removing unsafe).

---

## Priority order for action

If I were sequencing this work:

1. **Fix UB in script dispatch** (`core/script.rs`)
2. **Fix tree invariant in `set_children`** (`core/world.rs`)
3. **Fix `set_widget` poll init** (`core/world.rs`)
4. **Fix obvious correctness bugs** (Pause mapping; Inspector bindings)
5. **Decide event→render model** (always render vs conditional) and align API accordingly
6. **Binding precedence + layered modes**
7. **Unicode width correctness** (Render/Text)
8. **Performance cleanup** (effects stack allocations, layout reruns, dirty flags separation)

---

If you want, I can also propose concrete API diffs (trait signatures, deprecations, and migration path) to address the larger structural points while keeping downstream churn contained.
